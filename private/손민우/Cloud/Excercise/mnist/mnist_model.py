# -*- coding: utf-8 -*-
"""multi_worker_with_keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OM2xSxbsLXVoARXYI2orv75oA7RP9VkV

##### Copyright 2019 The TensorFlow Authors.
"""

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## Overview

#This tutorial demonstrates multi-worker distributed training with Keras model using `tf.distribute.Strategy` API. With the help of the strategies specifically designed for multi-worker training, a Keras model that was designed to run on single-worker can seamlessly work on multiple workers with minimal code change.

#[Distributed Training in TensorFlow](../../guide/distributed_training.ipynb) guide is available for an overview of the distribution strategies TensorFlow supports for those interested in a deeper understanding of `tf.distribute.Strategy` APIs.

## Setup

# First, setup TensorFlow and the necessary imports.

"""## Preparing dataset

Now, let's prepare the MNIST dataset from [TensorFlow Datasets](https://www.tensorflow.org/datasets). The [MNIST dataset](http://yann.lecun.com/exdb/mnist/) comprises 60,000
training examples and 10,000 test examples of the handwritten digits 0â€“9,
formatted as 28x28-pixel monochrome images.
"""
import tensorflow as tf

BUFFER_SIZE = 10000
BATCH_SIZE = 64
def make_datasets_unbatched():
  # Scaling MNIST data from (0, 255] to (0., 1.]
  if tf.__version__ == '2.0.0':
    import tensorflow_datasets as tfds
    def scale(image, label):
      image = tf.cast(image, tf.float32)
      image /= 255
      return image, label
    tfds.disable_progress_bar()
    datasets, info = tfds.load(name='mnist',
                              with_info=True,
                              as_supervised=True)

    return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)
  else:
    import mnist_dataset as dataset
    ds = dataset.train('/bg/mnist')
    ds = ds.cache().shuffle(buffer_size=50000)
    return ds
  
"""## Build the Keras model
Here we use `tf.keras.Sequential` API to build and compile a simple convolutional neural networks Keras model to train with our MNIST dataset.

Note: For a more comprehensive walkthrough of building Keras model, please see [TensorFlow Keras Guide](https://www.tensorflow.org/guide/keras#sequential_model).
"""

def build_and_compile_cnn_model(forward_only=False, lr=0.001):
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10, activation='softmax')
  ])
  if forward_only:
    return model
  optimizer = tf.keras.optimizers.SGD(learning_rate=lr)
  model.compile(
      loss=tf.keras.losses.sparse_categorical_crossentropy,
      optimizer=optimizer,
      metrics=['accuracy'])
  return model
